{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"Lab_14_DBSCAN.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"zsYUg_ollbnB"},"source":["# Phân cụm dựa trên mật độ (Density-Based Clustering)\n","\n","Thời lượng ước tính: **45** phút\n","\n","## Mục tiêu\n","\n","Sau khi hoàn thành lab này, bạn sẽ có thể:\n","\n","- Sử dụng DBSCAN để thực hiện phân cụm dựa trên mật độ\n","- Sử dụng Matplotlib để vẽ biểu đồ các cụm\n"]},{"cell_type":"markdown","metadata":{"id":"CK_NbLYDlbnU"},"source":["Hầu hết các kỹ thuật phân cụm truyền thống, chẳng hạn như k-means, phân cụm phân cấp (hierarchical) và mờ (fuzzy), có thể được sử dụng để nhóm dữ liệu mà không cần giám sát.\n","\n","Tuy nhiên, khi áp dụng cho các tác vụ có các cụm hình dạng bất kỳ hoặc các cụm trong cụm, các kỹ thuật truyền thống có thể không đạt được kết quả tốt. Tức là, các phần tử trong cùng một cụm có thể không có cùng độ tương tự hoặc hiệu suất kém.\n","Ngoài ra, Phân cụm dựa trên mật độ định vị các vùng có mật độ cao phân tách với các vùng có mật độ thấp. Mật độ trong ngữ cảnh này được định nghĩa là số điểm trong một bán kính nhất định.\n","\n","Trong phần này, trọng tâm chính sẽ là thao tác dữ liệu và thuộc tính của DBSCAN và quan sát kết quả phân cụm.\n"]},{"cell_type":"markdown","metadata":{"id":"dnuTwm-ulbnV"},"source":["Import các thư viện sau:\n","\n","<ul>\n","    <li> <b>numpy as np</b> </li>\n","    <li> <b>DBSCAN</b> từ <b>sklearn.cluster</b> </li>\n","    <li> <b>make_blobs</b> từ <b>sklearn.datasets.samples_generator</b> </li>\n","    <li> <b>StandardScaler</b> từ <b>sklearn.preprocessing</b> </li>\n","    <li> <b>matplotlib.pyplot as plt</b> </li>\n","</ul> <br>\n","Hãy nhớ <b>%matplotlib inline</b> để hiển thị các biểu đồ\n"]},{"cell_type":"code","metadata":{"id":"FrxjFEnjlbnV"},"source":["# Cài đặt thư viện basemap để phục vụ cho bài lab\n","# Lưu ý: \n","#     1. Nếu bạn thiết lập mỗi trường conda hãy đoạn code thứ nhất\n","#     2. Nếu bạn không thiết lập môi trường với anaconda hoặc sử dụng google colab hãy chạy đoạn code thứ hai\n","#     3. Sau khi cài đặt hãy restart runtime của notebook\n","\n","!conda install -c conda-forge basemap matplotlib==3.1 -y\n","!pip install basemap matplotlib==3.1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hoJPzWJOlbnW"},"source":["import numpy as np \n","from sklearn.cluster import DBSCAN \n","from sklearn.datasets import make_blobs \n","from sklearn.preprocessing import StandardScaler \n","import matplotlib.pyplot as plt \n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TRjB067albnX"},"source":["### Khởi tạo dữ liệu\n","\n","Hàm bên dưới sẽ tạo ra các điểm dữ liệu và yêu cầu các input sau:\n","\n","<ul>\n","    <li> <b>centroidLocation</b>: Tọa độ của các trọng tâm sẽ tạo ra dữ liệu ngẫu nhiên. </li>\n","    <ul> <li> Ví dụ: nhập: [[4,3], [2,-1], [-1,4]] </li> </ul>\n","    <li> <b>numSamples</b>: Số lượng điểm dữ liệu mà chúng ta muốn tạo ra, chia trên số lượng trọng tâm (số lượng trọng tâm được xác định trong centroidLocation) </li>\n","    <ul> <li> Ví dụ: 1500 </li> </ul>\n","    <li> <b>clusterDeviation</b>: Độ lệch chuẩn giữa các cụm. Độ lệch càng lớn thì khoảng cách càng xa. </li>\n","    <ul> <li> Ví dụ: 0.5 </li> </ul>\n","</ul>\n"]},{"cell_type":"code","metadata":{"id":"FekxLkC8lbnZ"},"source":["def createDataPoints(centroidLocation, numSamples, clusterDeviation):\n","    # Create random data and store in feature matrix X and response vector y.\n","    X, y = make_blobs(n_samples=numSamples, centers=centroidLocation, \n","                                cluster_std=clusterDeviation)\n","    \n","    # Standardize features by removing the mean and scaling to unit variance\n","    X = StandardScaler().fit_transform(X)\n","    return X, y"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XINGUCo4lbna"},"source":["Sử dụng <b>createDataPoints</b> với <b>3 input</b> và lưu trữ output vào các biến <b>X</b> và <b>y</b>."]},{"cell_type":"code","metadata":{"id":"dUJ2Gg3Ulbnb"},"source":["X, y = createDataPoints([[4,3], [2,-1], [-1,4]] , 1500, 0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MSxcST2Klbnc"},"source":["### Mô hình hóa\n","\n","DBSCAN là viết tắt của cụm từ Phân cụm không gian dựa trên mật độ của các ứng dụng có độ nhiễu. Kỹ thuật này là một trong những thuật toán phân cụm phổ biến nhất hoạt động dựa trên mật độ của đối tượng.\n","Ý tưởng là nếu một điểm cụ thể thuộc về một cụm, thì nó sẽ gần với rất nhiều điểm khác trong cụm đó.\n","\n","Nó hoạt động dựa trên 2 tham số: Epsilon và Minimum Points\n","\n","**Epsilon** xác định bán kính xác định mà nếu bao gồm đủ số điểm bên trong, ta gọi nó là dense area  \n","**minimumSamples** xác định số lượng điểm dữ liệu tối thiểu mà chúng ta muốn trong một vùng lân cận để xác định một cụm.\n"]},{"cell_type":"code","metadata":{"id":"ALgaNDlNlbnd"},"source":["epsilon = 0.3\n","minimumSamples = 7\n","db = DBSCAN(eps=epsilon, min_samples=minimumSamples).fit(X)\n","labels = db.labels_\n","labels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HzByjVoYlbnd"},"source":["### Phân biệt các ngoại lệ\n","\n","Hãy thay thế tất cả các phần tử bằng 'True' trong core_samples_mask nằm trong cụm, 'False' nếu các điểm là ngoại lệ.\n"]},{"cell_type":"code","metadata":{"id":"KVNJX8VIlbnd"},"source":["# Firts, create an array of booleans using the labels from db.\n","core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n","core_samples_mask[db.core_sample_indices_] = True\n","core_samples_mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r256s5gllbne"},"source":["# Number of clusters in labels, ignoring noise if present.\n","n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n","n_clusters_"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IfrcwkKilbnf"},"source":["# Remove repetition in labels by turning it into a set.\n","unique_labels = set(labels)\n","unique_labels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BjMJLO1slbnf"},"source":["### Trực quan hóa Dữ liệu\n"]},{"cell_type":"code","metadata":{"id":"i1GqAvDflbnf"},"source":["# Create colors for the clusters.\n","colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"XrYezSyjlbng"},"source":["# Plot the points with colors\n","for k, col in zip(unique_labels, colors):\n","    if k == -1:\n","        # Black used for noise.\n","        col = 'k'\n","\n","    class_member_mask = (labels == k)\n","\n","    # Plot the datapoints that are clustered\n","    xy = X[class_member_mask & core_samples_mask]\n","    plt.scatter(xy[:, 0], xy[:, 1],s=50, c=[col], marker=u'o', alpha=0.5)\n","\n","    # Plot the outliers\n","    xy = X[class_member_mask & ~core_samples_mask]\n","    plt.scatter(xy[:, 0], xy[:, 1],s=50, c=[col], marker=u'o', alpha=0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MJuOf_eMlbng"},"source":["## Thực hành\n","\n","Để hiểu sự khác biệt giữa phân cụm theo từng phần và dựa trên mật độ, hãy cố gắng phân cụm tập dữ liệu trên thành 3 cụm sử dụng k-Means.\n","Lưu ý: không tạo lại dữ liệu, sử dụng cùng một tập dữ liệu như trên.\n"]},{"cell_type":"code","metadata":{"id":"R-FDaCiYlbng"},"source":["# Nhập code của bạn ở đây\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZksjKN1Flbnh"},"source":["<details><summary>Click vào đây để xem lời giải</summary>\n","\n","```python\n","from sklearn.cluster import KMeans \n","k = 3\n","k_means3 = KMeans(init = \"k-means++\", n_clusters = k, n_init = 12)\n","k_means3.fit(X)\n","fig = plt.figure(figsize=(6, 4))\n","ax = fig.add_subplot(1, 1, 1)\n","for k, col in zip(range(k), colors):\n","    my_members = (k_means3.labels_ == k)\n","    plt.scatter(X[my_members, 0], X[my_members, 1],  c=col, marker=u'o', alpha=0.5)\n","plt.show()\n","\n","```\n","\n","</details>\n"]},{"cell_type":"markdown","metadata":{"id":"ZFpdUvYClbnh"},"source":["<h1 align=center> Phân cụm trạm thời tiết sử dụng DBSCAN & scikit-learning</h1>\n","<hr>\n","\n","DBSCAN đặc biệt rất tốt cho các tác vụ như xác định lớp trên bối cảnh không gian. Thuộc tính tuyệt vời của thuật toán DBSCAN là nó có thể tìm ra bất kỳ cụm hình dạng tùy ý nào mà không bị ảnh hưởng bởi noise (nhiễu). Ví dụ sau đây phân cụm vị trí của các trạm thời tiết ở Canada.\n","<Click 1>\n","Ví dụ, DBSCAN có thể được sử dụng ở đây để tìm nhóm các trạm có cùng điều kiện thời tiết. Như bạn có thể thấy, nó không chỉ tìm thấy các cụm có hình dạng tùy ý khác nhau mà còn có thể tìm thấy phần dày đặc hơn của các mẫu lấy dữ liệu làm trọng tâm bằng cách bỏ qua các khu vực ít mật độ hơn hoặc ít ồn hơn.\n","\n","Hãy bắt đầu xử lý dữ liệu. Chúng ta sẽ làm việc theo quy trình sau: </font>\n","\n","1.  Load dữ liệu\n","\n","- Tổng quan dữ liệu\n","- Làm sạch dữ liệu (data cleaning)\n","- Lựa chọn dữ liệu\n","- Phân cụm\n"]},{"cell_type":"markdown","metadata":{"id":"fUvbN43tlbnh"},"source":["### Về tập dữ liệu\n","\n","<h4 align = \"center\">\n","Giá trị môi trường Canada\n","hàng tháng trong tháng 7 - 2015\n","</h4>\n","<html>\n","<head>\n","<style>\n","table {\n","    font-family: arial, sans-serif;\n","    border-collapse: collapse;\n","    width: 100%;\n","}\n","\n","td, th {\n","    border: 1px solid #dddddd;\n","    text-align: left;\n","    padding: 8px;\n","}\n","\n","tr:nth-child(even) {\n","    background-color: #dddddd;\n","}\n","</style>\n","\n","</head>\n","<body>\n","\n","<table>\n","  <tr>\n","    <th>Ký hiệu trong bảng</th>\n","    <th>Định nghĩa</th>\n","  </tr>\n","  <tr>\n","    <td><font color = \"green\"><strong>Stn_Name</font></td>\n","    <td><font color = \"green\"><strong>Station Name</font</td>\n","  </tr>\n","  <tr>\n","    <td><font color = \"green\"><strong>Lat</font></td>\n","    <td><font color = \"green\"><strong>Latitude (North+, degrees)</font></td>\n","  </tr>\n","  <tr>\n","    <td><font color = \"green\"><strong>Long</font></td>\n","    <td><font color = \"green\"><strong>Longitude (West - , degrees)</font></td>\n","  </tr>\n","  <tr>\n","    <td>Prov</td>\n","    <td>Province</td>\n","  </tr>\n","  <tr>\n","    <td>Tm</td>\n","    <td>Mean Temperature (°C)</td>\n","  </tr>\n","  <tr>\n","    <td>DwTm</td>\n","    <td>Days without Valid Mean Temperature</td>\n","  </tr>\n","  <tr>\n","    <td>D</td>\n","    <td>Mean Temperature difference from Normal (1981-2010) (°C)</td>\n","  </tr>\n","  <tr>\n","    <td><font color = \"black\">Tx</font></td>\n","    <td><font color = \"black\">Highest Monthly Maximum Temperature (°C)</font></td>\n","  </tr>\n","  <tr>\n","    <td>DwTx</td>\n","    <td>Days without Valid Maximum Temperature</td>\n","  </tr>\n","  <tr>\n","    <td><font color = \"black\">Tn</font></td>\n","    <td><font color = \"black\">Lowest Monthly Minimum Temperature (°C)</font></td>\n","  </tr>\n","  <tr>\n","    <td>DwTn</td>\n","    <td>Days without Valid Minimum Temperature</td>\n","  </tr>\n","  <tr>\n","    <td>S</td>\n","    <td>Snowfall (cm)</td>\n","  </tr>\n","  <tr>\n","    <td>DwS</td>\n","    <td>Days without Valid Snowfall</td>\n","  </tr>\n","  <tr>\n","    <td>S%N</td>\n","    <td>Percent of Normal (1981-2010) Snowfall</td>\n","  </tr>\n","  <tr>\n","    <td><font color = \"green\"><strong>P</font></td>\n","    <td><font color = \"green\"><strong>Total Precipitation (mm)</font></td>\n","  </tr>\n","  <tr>\n","    <td>DwP</td>\n","    <td>Days without Valid Precipitation</td>\n","  </tr>\n","  <tr>\n","    <td>P%N</td>\n","    <td>Percent of Normal (1981-2010) Precipitation</td>\n","  </tr>\n","  <tr>\n","    <td>S_G</td>\n","    <td>Snow on the ground at the end of the month (cm)</td>\n","  </tr>\n","  <tr>\n","    <td>Pd</td>\n","    <td>Number of days with Precipitation 1.0 mm or more</td>\n","  </tr>\n","  <tr>\n","    <td>BS</td>\n","    <td>Bright Sunshine (hours)</td>\n","  </tr>\n","  <tr>\n","    <td>DwBS</td>\n","    <td>Days without Valid Bright Sunshine</td>\n","  </tr>\n","  <tr>\n","    <td>BS%</td>\n","    <td>Percent of Normal (1981-2010) Bright Sunshine</td>\n","  </tr>\n","  <tr>\n","    <td>HDD</td>\n","    <td>Degree Days below 18 °C</td>\n","  </tr>\n","  <tr>\n","    <td>CDD</td>\n","    <td>Degree Days above 18 °C</td>\n","  </tr>\n","  <tr>\n","    <td>Stn_No</td>\n","    <td>Climate station identifier (first 3 digits indicate   drainage basin, last 4 characters are for sorting alphabetically).</td>\n","  </tr>\n","  <tr>\n","    <td>NA</td>\n","    <td>Not Available</td>\n","  </tr>\n","\n","</table>\n","\n","</body>\n","</html>\n"]},{"cell_type":"markdown","metadata":{"id":"b46zxt8dlbnj"},"source":["### 1. Load tập dữ liệu\n","\n","Chúng ta sẽ nhập .csv sau đó tạo các cột cho năm, tháng và ngày.\n"]},{"cell_type":"code","metadata":{"id":"QLGkIBnvlbnk"},"source":["import csv\n","import pandas as pd\n","import numpy as np\n","\n","filename='weather-stations20140101-20141231.csv'\n","\n","#Read csv\n","pdf = pd.read_csv(filename)\n","pdf.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ksuwgd4_lbnk"},"source":["### 2. Làm sạch dữ liệu \n","\n","Hãy loại bỏ các hàng không có bất kỳ giá trị nào trong trường **Tm**.\n"]},{"cell_type":"code","metadata":{"id":"jxd8lCmNlbnk"},"source":["pdf = pdf[pd.notnull(pdf[\"Tm\"])]\n","pdf = pdf.reset_index(drop=True)\n","pdf.head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mRGBcqz2lbnl"},"source":["### 3. Trực quan hóa\n","\n","Trực quan hóa các trạm trên bản đồ bằng gói basemap. Bộ công cụ basemap của matplotlib là một thư viện để vẽ trên bản đồ dữ liệu 2D trong Python. Basemap không tự thực hiện bất kỳ biểu đồ nào nhưng cung cấp các phương tiện để chuyển đổi tọa độ thành phép chiếu bản đồ.\n","\n","Vui lòng lưu ý rằng kích thước của mỗi điểm dữ liệu đại diện cho mức trung bình của nhiệt độ tối đa cho mỗi trạm trong một năm.\n"]},{"cell_type":"code","metadata":{"id":"dVdl2dQMlbnl"},"source":["from mpl_toolkits.basemap import Basemap\n","import matplotlib.pyplot as plt\n","from pylab import rcParams\n","%matplotlib inline\n","rcParams['figure.figsize'] = (14,10)\n","\n","llon=-140\n","ulon=-50\n","llat=40\n","ulat=65\n","\n","pdf = pdf[(pdf['Long'] > llon) & (pdf['Long'] < ulon) & (pdf['Lat'] > llat) &(pdf['Lat'] < ulat)]\n","\n","my_map = Basemap(projection='merc',\n","            resolution = 'l', area_thresh = 1000.0,\n","            llcrnrlon=llon, llcrnrlat=llat, #min longitude (llcrnrlon) and latitude (llcrnrlat)\n","            urcrnrlon=ulon, urcrnrlat=ulat) #max longitude (urcrnrlon) and latitude (urcrnrlat)\n","\n","my_map.drawcoastlines()\n","my_map.drawcountries()\n","# my_map.drawmapboundary()\n","my_map.fillcontinents(color = 'white', alpha = 0.3)\n","my_map.shadedrelief()\n","\n","# To collect data based on stations        \n","\n","xs,ys = my_map(np.asarray(pdf.Long), np.asarray(pdf.Lat))\n","pdf['xm']= xs.tolist()\n","pdf['ym'] =ys.tolist()\n","\n","#Visualization1\n","for index,row in pdf.iterrows():\n","#   x,y = my_map(row.Long, row.Lat)\n","   my_map.plot(row.xm, row.ym,markerfacecolor =([1,0,0]),  marker='o', markersize= 5, alpha = 0.75)\n","#plt.text(x,y,stn)\n","plt.show()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hj-G78gdlbnm"},"source":["### 4. Nhóm các trạm dựa trên vị trí của chúng, tức là Vĩ độ và Kinh độ\n","\n","**DBSCAN** của thư viện sklearn có thể chạy phân cụm DBSCAN từ mảng vectơ hoặc ma trận khoảng cách. Trong trường hợp này, hãy truyền nó vào mảng Numpy Clus_dataSet để tìm các mẫu lõi có mật độ cao và mở rộng các cụm từ chúng."]},{"cell_type":"code","metadata":{"id":"FKaEU3g6lbnm"},"source":["from sklearn.cluster import DBSCAN\n","import sklearn.utils\n","from sklearn.preprocessing import StandardScaler\n","sklearn.utils.check_random_state(1000)\n","Clus_dataSet = pdf[['xm','ym']]\n","Clus_dataSet = np.nan_to_num(Clus_dataSet)\n","Clus_dataSet = StandardScaler().fit_transform(Clus_dataSet)\n","\n","# Compute DBSCAN\n","db = DBSCAN(eps=0.15, min_samples=10).fit(Clus_dataSet)\n","core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n","core_samples_mask[db.core_sample_indices_] = True\n","labels = db.labels_\n","pdf[\"Clus_Db\"]=labels\n","\n","realClusterNum=len(set(labels)) - (1 if -1 in labels else 0)\n","clusterNum = len(set(labels)) \n","\n","\n","# A sample of clusters\n","pdf[[\"Stn_Name\",\"Tx\",\"Tm\",\"Clus_Db\"]].head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H0oT7CCylbnm"},"source":["Như bạn có thể thấy đối với các ngoại lai, nhãn cụm là -1\n"]},{"cell_type":"code","metadata":{"id":"1mClWz64lbnm"},"source":["set(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n92dKIwKlbnn"},"source":["### 5. Trực quan hóa các cụm dựa trên vị trí\n","\n","Bây giờ, chúng ta có thể trực quan hóa các cụm bằng basemap:\n"]},{"cell_type":"code","metadata":{"id":"m6Ed9Pk8lbnn"},"source":["from mpl_toolkits.basemap import Basemap\n","import matplotlib.pyplot as plt\n","from pylab import rcParams\n","%matplotlib inline\n","rcParams['figure.figsize'] = (14,10)\n","\n","my_map = Basemap(projection='merc',\n","            resolution = 'l', area_thresh = 1000.0,\n","            llcrnrlon=llon, llcrnrlat=llat, #min longitude (llcrnrlon) and latitude (llcrnrlat)\n","            urcrnrlon=ulon, urcrnrlat=ulat) #max longitude (urcrnrlon) and latitude (urcrnrlat)\n","\n","my_map.drawcoastlines()\n","my_map.drawcountries()\n","#my_map.drawmapboundary()\n","my_map.fillcontinents(color = 'white', alpha = 0.3)\n","my_map.shadedrelief()\n","\n","# To create a color map\n","colors = plt.get_cmap('jet')(np.linspace(0.0, 1.0, clusterNum))\n","\n","\n","\n","#Visualization1\n","for clust_number in set(labels):\n","    c=(([0.4,0.4,0.4]) if clust_number == -1 else colors[np.int(clust_number)])\n","    clust_set = pdf[pdf.Clus_Db == clust_number]                    \n","    my_map.scatter(clust_set.xm, clust_set.ym, color =c,  marker='o', s= 20, alpha = 0.85)\n","    if clust_number != -1:\n","        cenx=np.mean(clust_set.xm) \n","        ceny=np.mean(clust_set.ym) \n","        plt.text(cenx,ceny,str(clust_number), fontsize=25, color='red',)\n","        print (\"Cluster \"+str(clust_number)+', Avg Temp: '+ str(np.mean(clust_set.Tm)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EsR_fqu_lbnp"},"source":["### 6. Phân nhóm các trạm dựa trên vị trí, nhiệt độ trung bình, nhiệt độ tối đa và tối thiểu\n","\n","Trong phần này, chúng ta chạy lại DBSCAN, nhưng trên tập dữ liệu 5 chiều:\n"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"VClIKf0Dlbnq"},"source":["from sklearn.cluster import DBSCAN\n","import sklearn.utils\n","from sklearn.preprocessing import StandardScaler\n","sklearn.utils.check_random_state(1000)\n","Clus_dataSet = pdf[['xm','ym','Tx','Tm','Tn']]\n","Clus_dataSet = np.nan_to_num(Clus_dataSet)\n","Clus_dataSet = StandardScaler().fit_transform(Clus_dataSet)\n","\n","# Compute DBSCAN\n","db = DBSCAN(eps=0.3, min_samples=10).fit(Clus_dataSet)\n","core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n","core_samples_mask[db.core_sample_indices_] = True\n","labels = db.labels_\n","pdf[\"Clus_Db\"]=labels\n","\n","realClusterNum=len(set(labels)) - (1 if -1 in labels else 0)\n","clusterNum = len(set(labels)) \n","\n","\n","# A sample of clusters\n","pdf[[\"Stn_Name\",\"Tx\",\"Tm\",\"Clus_Db\"]].head(5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aXFcbYOnlbnr"},"source":["### 7. Trực quan hóa các cụm dựa trên vị trí và nhiệt độ\n"]},{"cell_type":"code","metadata":{"id":"3IYlLxi5lbnr"},"source":["from mpl_toolkits.basemap import Basemap\n","import matplotlib.pyplot as plt\n","from pylab import rcParams\n","%matplotlib inline\n","rcParams['figure.figsize'] = (14,10)\n","\n","my_map = Basemap(projection='merc',\n","            resolution = 'l', area_thresh = 1000.0,\n","            llcrnrlon=llon, llcrnrlat=llat, #min longitude (llcrnrlon) and latitude (llcrnrlat)\n","            urcrnrlon=ulon, urcrnrlat=ulat) #max longitude (urcrnrlon) and latitude (urcrnrlat)\n","\n","my_map.drawcoastlines()\n","my_map.drawcountries()\n","#my_map.drawmapboundary()\n","my_map.fillcontinents(color = 'white', alpha = 0.3)\n","my_map.shadedrelief()\n","\n","# To create a color map\n","colors = plt.get_cmap('jet')(np.linspace(0.0, 1.0, clusterNum))\n","\n","\n","\n","#Visualization1\n","for clust_number in set(labels):\n","    c=(([0.4,0.4,0.4]) if clust_number == -1 else colors[np.int(clust_number)])\n","    clust_set = pdf[pdf.Clus_Db == clust_number]                    \n","    my_map.scatter(clust_set.xm, clust_set.ym, color =c,  marker='o', s= 20, alpha = 0.85)\n","    if clust_number != -1:\n","        cenx=np.mean(clust_set.xm) \n","        ceny=np.mean(clust_set.ym) \n","        plt.text(cenx,ceny,str(clust_number), fontsize=25, color='red',)\n","        print (\"Cluster \"+str(clust_number)+', Avg Temp: '+ str(np.mean(clust_set.Tm)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IGt0jROylbns"},"source":["### Cảm ơn bạn đã hoàn thành lab này!\n","\n","Nguồn bài Lab: **IBM**"]}]}